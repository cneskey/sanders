Package: sanders
Type: Package
Title: Web-scraping and Web-crawling Content Parsing, Validation and Sanitization Helpers
Version: 0.1.0
Date: 2017-09-21
Author: Bob Rudis (bob@rud.is)
Maintainer: Bob Rudis <bob@rud.is>
Description: When researchers crawl/scrape the web for content they are talking to
    strange computers running software created by a diverse array of humans. Content --
    even content that is supposed to adhere to internet stadards -- can have very
    rough edges that need to be smoothed out to be useful and potentially less harmful
    to the systems running the scraping and analysis code. Methods are provided that
    sand off the rough edges of many different types of scraped content and metadata.
URL: https://github.com/hrbrmstr/sanders
BugReports: https://github.com/hrbrmstr/sanders/issues
License: AGPL
Suggests:
    testthat,
    covr
Depends:
    R (>= 3.2.0)
Imports:
    tibble,
    stringi
RoxygenNote: 6.0.1
